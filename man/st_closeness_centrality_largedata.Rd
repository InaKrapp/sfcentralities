% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/st_closeness_centrality.R
\name{st_closeness_centrality_largedata}
\alias{st_closeness_centrality_largedata}
\title{A function to find closeness centrality in large dodgr graphs using batch processing}
\usage{
st_closeness_centrality_largedata(graph, normalized, chunk_size = 1000)
}
\arguments{
\item{graph}{A `dodgr_streetnet` graph.}

\item{normalized}{Logical. If `TRUE`, normalized closeness centrality is computed
(mean of distances). If `FALSE`, unnormalized closeness is computed (sum of distances).}

\item{chunk_size}{The number of vertices for which distances should be calculated
at once in each iteration. Defaults to `1000`. This directly controls memory usage.}
}
\value{
A numeric vector of closeness values, one for each vertex in the graph.
}
\description{
This helper function calculates closeness centrality for each vertex in a large
`dodgr` graph by processing distances in batches. This approach reduces memory
consumption compared to calculating all-pairs distances at once, which can
result in a very large distance matrix (n^2).
}
\examples{
library(dodgr)
library(sf)
# Create a sample graph (using hampi, which is small, but demonstrates the function)
graph_hampi <- dodgr::weight_streetnet(hampi, wt_profile = "foot")

# Calculate closeness using the batch processing function
closeness_values_batched <- st_closeness_centrality_largedata(graph_hampi,
 normalized = TRUE, chunk_size = 50)
head(closeness_values_batched)
}
